{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = \"/Users/gaurav/Desktop/Kaggle/imdb/imdb-movie-reviews-dataset/aclImdb/train/pos/\"\n",
    "negative = \"/Users/gaurav/Desktop/Kaggle/imdb/imdb-movie-reviews-dataset/aclImdb/train/neg/\"\n",
    "\n",
    "test_positive = \"/Users/gaurav/Desktop/Kaggle/imdb/imdb-movie-reviews-dataset/aclImdb/test/pos/\"\n",
    "test_negative = \"/Users/gaurav/Desktop/Kaggle/imdb/imdb-movie-reviews-dataset/aclImdb/test/neg/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content(dir, filename):\n",
    "    path=dir+filename\n",
    "#     print (path)\n",
    "    doc = file(path, 'r')\n",
    "    rating = filename.split(\"_\")[1].split('.')[0]\n",
    "    text = doc.read()\n",
    "    return text, rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews(dir, dic):\n",
    "    for x in os.listdir(dir):\n",
    "        text_rating = content(dir, x)\n",
    "#         print (rev, rating)\n",
    "        dic.append(text_rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate(x):\n",
    "    if int(x[1])>5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(text):\n",
    "    stop = set(stopwords.words(\"english\"))\n",
    "    text = re.sub(\"<[a-z0-9]+>\", \" \", text)\n",
    "    text = re.sub(\"[0-9]+\", \"NUMBER\", text)\n",
    "    text = re.sub(\"[.,#_%$&\\\"\\'\\/\\(\\):!]\", \"\", text)\n",
    "    words = text.split()\n",
    "    words_filtered = [x for x in words if x not in stop]\n",
    "    text = \" \".join(words_filtered)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = []\n",
    "get_reviews(positive, review)\n",
    "get_reviews(negative, review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_review = []\n",
    "get_reviews(test_positive, test_review)\n",
    "get_reviews(test_negative, test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(review, columns=[\"review\", \"rating\"])\n",
    "df_test = pd.DataFrame(test_review, columns=[\"review\", \"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"class\"] = df.apply(rate, axis=1)\n",
    "df_test[\"class\"] = df_test.apply(rate, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_cleaned'] = df['review'].apply(lambda x: clean_data(x))\n",
    "df_test['review_cleaned'] = df_test['review'].apply(lambda x: clean_data(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"imdb/train.csv\", index=False)\n",
    "df_test.to_csv(\"imdb/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"imdb/train.csv\")\n",
    "df_test = pd.read_csv(\"imdb/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(vect, clf, params, df, df_test):\n",
    "    bow = vect.fit_transform(df['review_cleaned'].tolist())\n",
    "    bow_test = vect.transform(df_test['review_cleaned'].tolist())\n",
    "    print(\"Number of features: \" + str(len(vect.get_feature_names())))\n",
    "    model = GridSearchCV(clf, params, cv=2)\n",
    "    model.fit(bow, df['class'])\n",
    "    print(\"Best estimator: \\n\")\n",
    "    print(model.best_estimator_)\n",
    "    preds = model.predict(bow_test)\n",
    "    score = accuracy_score(df_test['class'], preds)\n",
    "    return model, preds, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify2(vect, clf, df, df_test):\n",
    "    bow = vect.fit_transform(df['review_cleaned'].tolist())\n",
    "    bow_test = vect.transform(df_test['review_cleaned'].tolist())\n",
    "    print(\"Number of features: \" + str(len(vect.get_feature_names())))\n",
    "#     model = GridSearchCV(clf, params, cv=2)\n",
    "    clf.fit(bow, df['class'])\n",
    "    preds = clf.predict(bow_test)\n",
    "    score = accuracy_score(df_test['class'], preds)\n",
    "    return clf, preds, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 10000\n",
      "Best estimator: \n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=10000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "Accuracy: 0.71348\n",
      "Wall time: 4min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vect = CountVectorizer(min_df=5, max_features=10000)\n",
    "tc = tree.DecisionTreeClassifier()\n",
    "parameters = {'max_features':(1000, 5000, 10000)}\n",
    "tc, preds, score = classify(vect, tc, parameters, df, df_test)\n",
    "print \"Accuracy: \" + str(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 10000\n",
      "Best estimator: \n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=5000, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "Accuracy: 0.71208\n",
      "Wall time: 4min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vect = CountVectorizer(min_df=5, max_features=10000, ngram_range=(1,2))\n",
    "tc = tree.DecisionTreeClassifier()\n",
    "parameters = {'max_features':(1000, 5000, 9999)}\n",
    "tc2, preds, score = classify(vect, tc, parameters, df, df_test)\n",
    "print \"Accuracy: \" + str(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 102215\n",
      "Best estimator: \n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=9999, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "Accuracy: 0.717\n",
      "Wall time: 2min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vect = TfidfVectorizer(min_df=5, ngram_range=(1,2))\n",
    "tc = tree.DecisionTreeClassifier()\n",
    "parameters = {'max_features':(1000, 5000, 9999)}\n",
    "tc3, preds, score = classify(vect, tc, parameters, df, df_test)\n",
    "print \"Accuracy: \" + str(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 10000\n",
      "Best estimator: \n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Accuracy: 0.85352\n",
      "Wall time: 17min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vect = TfidfVectorizer(min_df=5, ngram_range=(1,2), max_features=10000)\n",
    "rfc = RandomForestClassifier(n_estimators=200)\n",
    "parameters = {'n_estimators':(50, 100, 200)}\n",
    "rf, preds, score = classify(vect, rfc, parameters, df, df_test)\n",
    "print \"Accuracy: \" + str(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 10000\n",
      "Best estimator: \n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "Accuracy: 0.8872\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vect = TfidfVectorizer(min_df=5, ngram_range=(1,2), max_features=10000)\n",
    "lr2 = LogisticRegression()\n",
    "parameters = {}\n",
    "lr2, preds, score = classify(vect, lr2, parameters, df, df_test)\n",
    "print \"Accuracy: \" + str(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 10000\n",
      "Accuracy: 0.85832\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vect = CountVectorizer(min_df=5, ngram_range=(1,2), max_features=10000)\n",
    "lr = LogisticRegression()\n",
    "lr, preds, score = classify2(vect, lr, df, df_test)\n",
    "print \"Accuracy: \" + str(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coef(word, vect, model):\n",
    "    i=0\n",
    "    index=-1\n",
    "    for x in vect.get_feature_names():\n",
    "        if x==word:\n",
    "            index = i\n",
    "        i=i+1\n",
    "#     print(\"Word not found in features\")\n",
    "    if index != -1:\n",
    "        print(\"Weight of \" + word + \": \" + str(model.coef_[0][index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight of excellent: 1.1407312792412023\n",
      "Weight of worst: -1.9396562892559814\n",
      "Weight of bad: -0.7057011326587759\n"
     ]
    }
   ],
   "source": [
    "get_coef(\"excellent\", vect, lr)\n",
    "get_coef(\"worst\", vect, lr)\n",
    "get_coef(\"bad\", vect, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vect = TfidfVectorizer(min_df=5, ngram_range=(1,2), max_features=10000)\n",
    "bow = vect.fit_transform(df['review_cleaned'].tolist())\n",
    "bow_test = vect.transform(df_test['review_cleaned'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.80532\n",
      "Wall time: 21min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nb = GaussianNB()\n",
    "nb.fit(bow.toarray(), df['class'])\n",
    "preds = nb.predict(bow_test.toarray())\n",
    "score = accuracy_score(df_test['class'], preds)\n",
    "print \"Accuracy: \" + str(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
